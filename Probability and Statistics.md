概率：已知模型和参数，推数据。
-去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 举个例子，我想研究怎么养猪（模型是猪），我选好了想养的品种、喂养方式、猪棚的设计等等（选择参数），我想知道我养出来的猪大概能有多肥，肉质怎么样（预测结果）。
统计：已知数据，推模型和参数
-有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉（这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等（推测模型参数）。
https://blog.csdn.net/u011508640/article/details/72815981

## 极大似然估计（Maximum Likelyhood Estimation）MLE
**贝叶斯公式**
$$ P(A|B)=\frac{P(B|A)P(A)}{P(B)} $$
$$ P(A|B)=\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|-A)P(-A)} $$
其中A是先发生的事情，B是后发生的事情。A是因，B是果。
所以P(A)是先验概率。
贝叶斯公式就是说，如果观察到了果，那么是这个A的因的概率是多少？


**似然函数：**
$$ P(x|\theta) $$
其中，P是模型，$$x$$是事件，或者某一个具体的数据，$$\theta$$是概率模型的参数
如果$$\theta$$是已知的，$$x$$是变量，这个函数就叫概率函数
如果$$x$$是已知的，$$\theta$$是变量，这个函数就叫似然函数
$$P(\theta|x)$$:已知$$x$$,求$$\theta$$,这个是后验概率。相当于先知道结果了，求这个结果下是某个原因的概率，或者这个结果下，是某个$$\hat \theta $$的概率。
** 极大似然估计 **
抛硬币：
假设出现正面的概率是$$\theta$$
抛十次的结果：反正正正正反正正正反
那么，$$\theta$$应该是多少呢？
似然函数：
$$ P(x|\theta)=(1-\theta)*\theta*\theta*\theta*\theta*(1-\theta*)\theta*\theta\theta*(1-\theta)=\theta^7(1-\theta)^3 =f(\theta) $$

画出$$f(\theta)$$图像，为凸函数，在$$\theta=0.7$$时取得最大值。

这就是极大似然估计。取似然函数最大值，即最有可能发生此结果的参数值。
但是，贝叶斯学派是另一种观点，加入了先验概率。谁不知道$$\theta=0.5 $$啊。
这就是我们的先验认知。我们以前的经验告诉我们。
## 最大后验概率估计(Maximum A Proteriori) MAP

最大似然函数是使得$$ P(x|\theta)$$最大
最大后验概率是使得$$ P(\theta|x)$$最大
$$ P(\theta|x)=\frac{P(x|\theta)*P(\theta)}{P(x)} $$
由于$$P(x)$$已经发生，是可以通过数据集知道的值。故为常数.
需要$$ P(x|\theta)*P(\theta) $$最大
求得的θ不单单让似然函数大，θ自己出现的先验概率也得大。
假设P(θ) 为均值0.5，方差0.1的高斯函数
那么函数图像为。。。
如果$$ P(\theta=0.5)=1,那无论怎么做实验，使用MAP估计出来都是θ=0.5。这也说明，一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到）
